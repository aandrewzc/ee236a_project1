{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "236A_project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn2vY1_6D4BI"
      },
      "source": [
        "\"\"\"\n",
        "ECE 236A Project 1, MyClassifier.py template. Note that you should change the\n",
        "name of this file to MyClassifier_16.py\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "\n",
        "\n",
        "class MyClassifier:\n",
        "    def __init__(self,K,M):\n",
        "        self.K = K  #Number of classes\n",
        "        self.M = M  #Number of features\n",
        "        self.W = []\n",
        "        self.w = []\n",
        "        \n",
        "    def train(self, p, train_data, train_label):\n",
        "        # THIS IS WHERE YOU SHOULD WRITE YOUR TRAINING FUNCTION\n",
        "        #\n",
        "        # The inputs to this function are:\n",
        "        #\n",
        "        # self: a reference to the classifier object.\n",
        "        # train_data: a matrix of dimesions N_train x M, where N_train\n",
        "        # is the number of inputs used for training. Each row is an\n",
        "        # input vector.\n",
        "        # trainLabel: a vector of length N_train. Each element is the\n",
        "        # label for the corresponding input column vector in trainData.\n",
        "        #\n",
        "        # Make sure that your code sets the classifier parameters after\n",
        "        # training. For example, your code should include a line that\n",
        "        # looks like \"self.W = a\" and \"self.w = b\" for some variables \"a\"\n",
        "        # and \"b\".\n",
        "        print(\"Training classifier\")\n",
        "        N_train = train_data.shape[0]\n",
        "        print(\"# of inputs: \", N_train)\n",
        "        #compute W and w\n",
        "\n",
        "        \n",
        "    def f(self,input):\n",
        "        # THIS IS WHERE YOU SHOULD WRITE YOUR CLASSIFICATION FUNCTION\n",
        "        #\n",
        "        # The inputs of this function are:\n",
        "        #\n",
        "        # input: the input to the function f(*), equal to g(y) = W^T y + w\n",
        "        #\n",
        "        # The outputs of this function are:\n",
        "        #\n",
        "        # s: this should be a scalar equal to the class estimated from\n",
        "        # the corresponding input data point, equal to f(W^T y + w)\n",
        "        # You should also check if the classifier is trained i.e. self.W and\n",
        "        # self.w are nonempty\n",
        "        if not self.W or not self.w:\n",
        "          return None\n",
        "        \n",
        "        #TODO: change this to our generalized classifier\n",
        "        if input > 0:\n",
        "          s = 1\n",
        "        else:\n",
        "          s = 0 \n",
        "\n",
        "        return s\n",
        "\n",
        "\n",
        "    def classify(self,test_data):\n",
        "        # THIS FUNCTION OUTPUTS ESTIMATED CLASSES FOR A DATA MATRIX\n",
        "        # \n",
        "        # The inputs of this function are:\n",
        "        # self: a reference to the classifier object.\n",
        "        # test_data: a matrix of dimensions N_test x M, where N_test\n",
        "        # is the number of inputs used for training. Each row is an\n",
        "        # input vector.\n",
        "        #\n",
        "        #\n",
        "        # The outputs of this function are:\n",
        "        #\n",
        "        # test_results: this should be a vector of length N_test,\n",
        "        # containing the estimations of the classes of all the N_test\n",
        "        # inputs.\n",
        "        print(\"Testing classifier\")\n",
        "        N_test = test_data.shape[0]\n",
        "        print(\"# of inputs: \", N_train)\n",
        "        \n",
        "        test_results = []\n",
        "        for image in test_data:\n",
        "          #TODO: alter this math depending on size of W, w\n",
        "          g = np.transpose(self.W, image) + self.w\n",
        "          classification = self.f(g)\n",
        "          test_results.append(classification)\n",
        "\n",
        "        return test_results\n",
        "    \n",
        "\n",
        "    def TestCorrupted(self,p,test_data):\n",
        "        # THIS FUNCTION OUTPUTS ESTIMATED CLASSES FOR A DATA MATRIX\n",
        "        #\n",
        "        #\n",
        "        # The inputs of this function are:\n",
        "        #\n",
        "        # self: a reference to the classifier object.\n",
        "        # test_data: a matrix of dimesions N_test x M, where N_test\n",
        "        # is the number of inputs used for training. Each row is an\n",
        "        # input vector.\n",
        "        #\n",
        "        # p:erasure probability\n",
        "        #\n",
        "        #\n",
        "        # The outputs of this function are:\n",
        "        #\n",
        "        # test_results: this should be a vector of length N_test,\n",
        "        # containing the estimations of the classes of all the N_test\n",
        "        # inputs.\n",
        "        \n",
        "        print() #you can erase this line"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrdB5pImPwXq",
        "outputId": "7c593c7e-494e-490f-f24a-6554b91004ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load MNIST data\n",
        "csv_train = 'sample_data/mnist_train_small.csv'\n",
        "csv_test = 'sample_data/mnist_test.csv'\n",
        "# csv_train = '/content/drive/My Drive/Colab Notebooks/mnist_train.csv'\n",
        "# csv_test = '/content/drive/My Drive/Colab Notebooks/mnist_test.csv'\n",
        "\n",
        "pd_train = pd.read_csv(csv_train)\n",
        "pd_test = pd.read_csv(csv_test)\n",
        "# print(\"Training Data:\\n\", pd_train)\n",
        "# print(\"Testing Data:\\n\", pd_test)\n",
        "\n",
        "np_train = pd_train.to_numpy()\n",
        "np_test = pd_test.to_numpy()\n",
        "\n",
        "print(\"Label #1:\", np_train[0,0])\n",
        "print(\"Image #1 Size:\", np_train[0,1:].size)\n",
        "\n",
        "train_labels = np_train[:,0] \n",
        "train_data = np_train[:,1:]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label #1: 5\n",
            "Image #1 Size: 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIupCqOIB1_6",
        "outputId": "44b4070e-753e-45d7-a994-67553e458a8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Initialize classifier with number of classes and features\n",
        "K = 2\n",
        "M = train_data.shape[1]  #784\n",
        "classifier = MyClassifier(K, M)\n",
        "\n",
        "#Extract data for only class 1 and class 7\n",
        "target_images = np.where((train_labels == 1) | (train_labels == 7))\n",
        "project_train_labels = train_labels[target_images]\n",
        "project_train_data = train_data[target_images]\n",
        "\n",
        "p = 0.6\n",
        "classifier.train(p, project_train_data, project_train_labels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of inputs:  4369\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}